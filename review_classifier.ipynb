{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Text Classifier Based on Amazon Product Reviews",
   "id": "dff11200de774c9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The Dataset used here is taken from https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews",
   "id": "eea51a3928b36590"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## includes and loging configuration",
   "id": "1ee1e136be93162a"
  },
  {
   "cell_type": "code",
   "id": "33ba7c8f8487cf57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T09:33:17.522318Z",
     "start_time": "2025-03-19T09:33:12.205895Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.info('Libraries imported successfully')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:03:17,519 - INFO - Libraries imported successfully\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Training Dataset",
   "id": "1512ead5f1cef29b"
  },
  {
   "cell_type": "code",
   "id": "load_train",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T09:33:33.972315Z",
     "start_time": "2025-03-19T09:33:17.554269Z"
    }
   },
   "source": [
    "logging.info('Loading training dataset from train.csv (no header assumed)')\n",
    "df_train = pd.read_csv('Data_sets/train.csv', header=None)\n",
    "logging.info(f'Training dataset shape: {df_train.shape}')\n",
    "print(df_train.head())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:03:17,555 - INFO - Loading training dataset from train.csv (no header assumed)\n",
      "2025-03-19 15:03:33,962 - INFO - Training dataset shape: (3600000, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                                                  1  \\\n",
      "0  2                     Stuning even for the non-gamer   \n",
      "1  2              The best soundtrack ever to anything.   \n",
      "2  2                                           Amazing!   \n",
      "3  2                               Excellent Soundtrack   \n",
      "4  2  Remember, Pull Your Jaw Off The Floor After He...   \n",
      "\n",
      "                                                   2  \n",
      "0  This sound track was beautiful! It paints the ...  \n",
      "1  I'm reading a lot of reviews saying that this ...  \n",
      "2  This soundtrack is my favorite music of all ti...  \n",
      "3  I truly like this soundtrack and I enjoy video...  \n",
      "4  If you've played the game, you know how divine...  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Processing Training Data",
   "id": "44c11a4263164079"
  },
  {
   "cell_type": "code",
   "id": "prepare_train",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T09:34:56.663813Z",
     "start_time": "2025-03-19T09:33:34.001647Z"
    }
   },
   "source": [
    "logging.info('Preparing training data: assuming first column is label and remaining columns are text features')\n",
    "\n",
    "y_train = np.array(df_train.iloc[:, 0]) - 1\n",
    "\n",
    "X_train_text = df_train.iloc[:, 1:]\n",
    "X_train_combined = X_train_text.apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
    "\n",
    "logging.info('Sample combined training text:')\n",
    "print(X_train_combined.iloc[0])\n",
    "\n",
    "X_train = X_train_combined\n",
    "logging.info(f'Total training samples: {len(X_train)}')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:03:34,005 - INFO - Preparing training data: assuming first column is label and remaining columns are text features\n",
      "2025-03-19 15:04:56,653 - INFO - Sample combined training text:\n",
      "2025-03-19 15:04:56,659 - INFO - Total training samples: 3600000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stuning even for the non-gamer This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Test Dataset",
   "id": "590355eede6b1f3a"
  },
  {
   "cell_type": "code",
   "id": "load_test",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T09:34:58.424814Z",
     "start_time": "2025-03-19T09:34:56.746623Z"
    }
   },
   "source": [
    "logging.info('Loading test dataset from test.csv (no header assumed)')\n",
    "df_test = pd.read_csv('Data_sets/test.csv', header=None)\n",
    "logging.info(f'Test dataset shape: {df_test.shape}')\n",
    "print(df_test.head())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:04:56,751 - INFO - Loading test dataset from test.csv (no header assumed)\n",
      "2025-03-19 15:04:58,419 - INFO - Test dataset shape: (400000, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                                                  1  \\\n",
      "0  2                                           Great CD   \n",
      "1  2  One of the best game music soundtracks - for a...   \n",
      "2  1                   Batteries died within a year ...   \n",
      "3  2              works fine, but Maha Energy is better   \n",
      "4  2                       Great for the non-audiophile   \n",
      "\n",
      "                                                   2  \n",
      "0  My lovely Pat has one of the GREAT voices of h...  \n",
      "1  Despite the fact that I have only played a sma...  \n",
      "2  I bought this charger in Jul 2003 and it worke...  \n",
      "3  Check out Maha Energy's website. Their Powerex...  \n",
      "4  Reviewed quite a bit of the combo players and ...  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test Data Preprocessing",
   "id": "a503e8dd66d7e682"
  },
  {
   "cell_type": "code",
   "id": "prepare_test",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T09:35:04.683929Z",
     "start_time": "2025-03-19T09:34:58.455036Z"
    }
   },
   "source": [
    "logging.info('Preparing test data: assuming first column is label and remaining columns are text features')\n",
    "\n",
    "y_test = np.array(df_test.iloc[:, 0]) - 1\n",
    "\n",
    "X_test_text = df_test.iloc[:, 1:]\n",
    "X_test_combined = X_test_text.apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
    "\n",
    "logging.info('Sample combined test text:')\n",
    "print(X_test_combined.iloc[0])\n",
    "\n",
    "X_test = X_test_combined\n",
    "logging.info(f'Total test samples: {len(X_test)}')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:04:58,458 - INFO - Preparing test data: assuming first column is label and remaining columns are text features\n",
      "2025-03-19 15:05:04,680 - INFO - Sample combined test text:\n",
      "2025-03-19 15:05:04,681 - INFO - Total test samples: 400000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great CD My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I'm in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life's hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Making Vector Encoding",
   "id": "420d6fd4c61ca25e"
  },
  {
   "cell_type": "code",
   "id": "vectorizer_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T09:42:25.650845Z",
     "start_time": "2025-03-19T09:35:04.706340Z"
    }
   },
   "source": "from sklearn.feature_extraction.text import TfidfVectorizer\n\nlogging.info('Initializing TfidfVectorizer with advanced parameters')\n\nvectorizer = TfidfVectorizer(\n    stop_words='english',\n    max_features=5000,\n    ngram_range=(1,2),\n    min_df=5,\n    max_df=0.8\n)\n\nlogging.info('Fitting vectorizer on training data')\nX_train_vect = vectorizer.fit_transform(X_train)\nlogging.info(f'Vectorized training data shape: {X_train_vect.shape}')\n\nlogging.info('Transforming test data using the fitted vectorizer')\nX_test_vect = vectorizer.transform(X_test)\nlogging.info(f'Vectorized test data shape: {X_test_vect.shape}')\n\nprint('Sample feature names:', vectorizer.get_feature_names_out()[:10])",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:05:08,242 - INFO - Initializing TfidfVectorizer with advanced parameters\n",
      "2025-03-19 15:05:08,243 - INFO - Fitting vectorizer on training data\n",
      "2025-03-19 15:12:01,371 - INFO - Vectorized training data shape: (3600000, 5000)\n",
      "2025-03-19 15:12:01,453 - INFO - Transforming test data using the fitted vectorizer\n",
      "2025-03-19 15:12:25,575 - INFO - Vectorized test data shape: (400000, 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample feature names: ['00' '000' '10' '10 minutes' '10 years' '100' '1000' '11' '12' '13']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Applying logistic regression",
   "id": "ebca4bcc705bbfa4"
  },
  {
   "cell_type": "code",
   "id": "model_training",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T09:42:36.481704Z",
     "start_time": "2025-03-19T09:42:25.862498Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logging.info('Initializing Logistic Regression model with adjusted regularization')\n",
    "\n",
    "model = LogisticRegression(max_iter=10000, C=10, random_state=42)\n",
    "\n",
    "logging.info('Training model on vectorized training data')\n",
    "model.fit(X_train_vect, y_train)\n",
    "logging.info('Model training completed')\n",
    "\n",
    "logging.info('Sample model coefficients:')\n",
    "print(model.coef_[0][:10])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:12:26,673 - INFO - Initializing Logistic Regression model with adjusted regularization\n",
      "2025-03-19 15:12:26,674 - INFO - Training model on vectorized training data\n",
      "2025-03-19 15:12:36,476 - INFO - Model training completed\n",
      "2025-03-19 15:12:36,477 - INFO - Sample model coefficients:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.71476247  0.28510761  0.05113642 -1.02188221  0.11386094  0.43268987\n",
      " -0.0690542   0.25810319 -0.22076131  0.14857283]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation of classifier",
   "id": "f83f3003f0507fd4"
  },
  {
   "cell_type": "code",
   "id": "evaluation_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T09:42:36.606925Z",
     "start_time": "2025-03-19T09:42:36.496581Z"
    }
   },
   "source": "from sklearn.metrics import classification_report, accuracy_score\n\nlogging.info('Evaluating model on test data')\ny_pred = model.predict(X_test_vect)\naccuracy = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred)\n\nlogging.info(f'Accuracy: {accuracy}')\nprint('Accuracy:', accuracy)\nprint('Classification Report:')\nprint(report)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:12:36,499 - INFO - Evaluating model on test data\n",
      "2025-03-19 15:12:36,603 - INFO - Accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8929\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89    200000\n",
      "           1       0.89      0.90      0.89    200000\n",
      "\n",
      "    accuracy                           0.89    400000\n",
      "   macro avg       0.89      0.89      0.89    400000\n",
      "weighted avg       0.89      0.89      0.89    400000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Custom Usage Based Evaluator Function",
   "id": "d5549b4413ecd157"
  },
  {
   "cell_type": "code",
   "id": "custom_test_function",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T09:42:36.811608Z",
     "start_time": "2025-03-19T09:42:36.805659Z"
    }
   },
   "source": [
    "def find_comment_type(comment_text):\n",
    "    \"\"\"Predict sentiment for a given comment string using the trained model.\"\"\"\n",
    "    if isinstance(comment_text, str):\n",
    "        comment_text = [comment_text]\n",
    "\n",
    "    comment_vect = vectorizer.transform(comment_text)\n",
    "\n",
    "    prediction = model.predict(comment_vect)\n",
    "    prediction_proba = model.predict_proba(comment_vect)\n",
    "\n",
    "    logging.info(f'Input comment: {comment_text[0]}')\n",
    "    logging.info(f'Prediction: {prediction}')\n",
    "    logging.info(f'Prediction probabilities: {prediction_proba}')\n",
    "    \n",
    "    print('Predicted class:', prediction[0])\n",
    "    print('Prediction probabilities:', prediction_proba)\n",
    "    return"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing",
   "id": "16d4541f1a443e7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T10:47:51.171424Z",
     "start_time": "2025-03-19T10:47:51.136261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "find_comment_type(\"Hey! worst product ever!\")\n",
    "find_comment_type(\"hey! this is very amazing! wow!\")"
   ],
   "id": "14c87c45fff4f218",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 16:17:51,160 - INFO - Input comment: Hey! worst product ever!\n",
      "2025-03-19 16:17:51,162 - INFO - Prediction: [0]\n",
      "2025-03-19 16:17:51,163 - INFO - Prediction probabilities: [[9.99774254e-01 2.25746466e-04]]\n",
      "2025-03-19 16:17:51,166 - INFO - Input comment: hey! this is very amazing! wow!\n",
      "2025-03-19 16:17:51,167 - INFO - Prediction: [1]\n",
      "2025-03-19 16:17:51,168 - INFO - Prediction probabilities: [[0.00344593 0.99655407]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n",
      "Prediction probabilities: [[9.99774254e-01 2.25746466e-04]]\n",
      "Predicted class: 1\n",
      "Prediction probabilities: [[0.00344593 0.99655407]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving Trained Model",
   "id": "e862456420ea8b68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T10:48:41.014652Z",
     "start_time": "2025-03-19T10:48:40.933305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'models/logistic_model.pkl')\n",
    "\n",
    "joblib.dump(vectorizer, 'models/tfidf_vectorizer.pkl')"
   ],
   "id": "3a6f1beddea9c077",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "77912ea3a54f5d69"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
